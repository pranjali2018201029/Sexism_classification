{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "K_Means.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHKyab2RGGx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import seaborn as sns\n",
        "\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMAqqlGMHpmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Centroid_init = [\"k-means++\", \"random\"]\n",
        "\n",
        "def K_Means(Data_Filepath, feature_list=[], No_Clusters=2, Centroid_init=\"k-means++\"):\n",
        "  \n",
        "  Caption_Data = pd.read_csv(Data_Filepath)\n",
        "  Data = Caption_Data[feature_list]\n",
        "  \n",
        "  kmeans = KMeans(n_clusters=No_Clusters, init=Centroid_init)\n",
        "  kmeans.fit(Data)\n",
        "  \n",
        "  Labels = kmeans.labels_\n",
        "  labels_df = pd.DataFrame(np.transpose(Labels), columns=[\"Label\"])\n",
        "  \n",
        "  labeled_data = pd.concat([Caption_Data, labels_df], axis=1)\n",
        "  Unique_labels = labeled_data[\"Label\"].unique()\n",
        "    \n",
        "  for label in Unique_labels:\n",
        "    class_data = labeled_data[labeled_data[\"Label\"]==label][[\"Caption_Tokens\",\"Label\"]]\n",
        "    \n",
        "    filepath = \"/content/class_\" + str(label) + \"_data.csv\"\n",
        "    class_data.to_csv(filepath)  \n",
        "    \n",
        "  return Labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PliSoNtLKP4c",
        "colab_type": "code",
        "outputId": "7191148c-dc12-4d4e-8310-a0e5695c9559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Data_Filepath = \"/content/Positive_Glove_Embeddings.csv\"\n",
        "\n",
        "Embedding_VectorSize = 300\n",
        "Feature_List = [str(i) for i in range(Embedding_VectorSize)]\n",
        "\n",
        "Labels = K_Means(Data_Filepath, feature_list=Feature_List)\n",
        "print(\"Labels: \", Labels)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels:  [0 0 0 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCg_cUGpZymj",
        "colab_type": "code",
        "outputId": "69c93824-5dc0-48e5-f122-d44beb07b869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "## Class 0\n",
        "\n",
        "Class_0_df = pd.read_csv(\"/content/class_0_data.csv\")\n",
        "print(\"CLASS 0 posts : \", Class_0_df.shape[0])\n",
        "\n",
        "## Class 1\n",
        "\n",
        "Class_1_df = pd.read_csv(\"/content/class_1_data.csv\")\n",
        "print(\"CLASS 1 posts : \", Class_1_df.shape[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CLASS 0 posts :  3363\n",
            "CLASS 1 posts :  285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcuInVq9fxUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}