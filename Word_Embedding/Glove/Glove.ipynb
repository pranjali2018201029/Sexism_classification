{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glove.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlsGlPk7gqlJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e65c6d8b-8400-4335-c432-4ed66e4113ba"
      },
      "source": [
        "## Install glove-python module\n",
        "!pip install -q glove-python"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▎                              | 10kB 19.6MB/s eta 0:00:01\r\u001b[K     |██▌                             | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███▊                            | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 40kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 81kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 266kB 2.7MB/s \n",
            "\u001b[?25h  Building wheel for glove-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIYlcYGBhiGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from glove import Corpus, Glove\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEdWYr7fojte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Trains Glove embeddings for words in text present in column (colname) in file (filepath)\n",
        "## Glove_Window = context length to be consider to find embedding of a word\n",
        "\n",
        "def Glove_Embeddings_Train(filepath, colname, Glove_window=10, Glove_Vector_Size=10, Glove_learning_rate=0.05, Glove_epochs=30, Glove_no_threads=4):\n",
        "  \n",
        "  df = pd.read_csv(filepath)\n",
        "  \n",
        "  data = []\n",
        "  for row in range(df.shape[0]):\n",
        "    post_caption = df.iloc[row][colname]\n",
        "    tokens = post_caption.split()\n",
        "    data.append(tokens)\n",
        "\n",
        "  data = np.array(data)\n",
        "  \n",
        "  corpus = Corpus()\n",
        "  corpus.fit(data, window=Glove_window)\n",
        "\n",
        "  glove = Glove(no_components=Glove_Vector_Size, learning_rate=Glove_learning_rate)\n",
        "  glove.fit(corpus.matrix, epochs=Glove_epochs, no_threads=Glove_no_threads, verbose=True)\n",
        "\n",
        "  glove.add_dictionary(corpus.dictionary)\n",
        "  \n",
        "  return glove\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3V7iMA1pvMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Input: glove object (object of trained model), text\n",
        "## Calculates word embedding for each word in text and returns mean of all vectors\n",
        "\n",
        "\n",
        "def Calculate_Glove_Embedding(glove, text):\n",
        "  \n",
        "  words = text.split()\n",
        "  text_embeddings = []\n",
        "  \n",
        "  for word in words:\n",
        "    ## Ignore if word that is not present in vocabulary appears in the text\n",
        "    if word in glove.dictionary:\n",
        "      word_embedding = glove.word_vectors[glove.dictionary[word]]\n",
        "      text_embeddings.append(word_embedding)\n",
        "  \n",
        "  text_embeddings = np.array(text_embeddings)\n",
        "  text_avg_embedding = np.mean(text_embeddings, axis=0)\n",
        "  \n",
        "  return text_avg_embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHO1eeQ5rYY8",
        "colab_type": "code",
        "outputId": "ad1a1919-27e2-427b-9aba-57174d6c5605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "## Train glove embeddings for given corpus and dump trained model object in pickle file \n",
        "## Load this pickle file in any other code, import this python module \n",
        "\n",
        "glove_obj = Glove_Embeddings_Train(\"/content/Filtered_Positive_Data.csv\", \"Caption_Tokens\", Glove_Vector_Size=300)\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open (\"/content/Trained_Glove_Model.pkl\", \"wb\") as file:\n",
        "  pickle.dump(glove_obj, file)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 4 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NwQIcXj0vy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Call this function in any python file where this module is imported \n",
        "## Input : GloveModel_filepath (trained model pickle file), Input_Data_filepath (Whose embeddings need to be calculated)\n",
        "## Output_Data_filepath: optional (if given, embeddings will be dumped in it. Should be csv file)\n",
        "## returns 2D dataframe with dimensions (No of samples in input, Vector size of embeddings)\n",
        "\n",
        "def Get_Glove_Embedding(GloveModel_filepath, Input_Data_filepath, colname, Output_Data_filepath=\"\"):\n",
        "  \n",
        "  with open(GloveModel_filepath, \"rb\") as ModelFile:\n",
        "    glove_object = pickle.load(ModelFile)\n",
        "    \n",
        "  data = pd.read_csv(Input_Data_filepath)\n",
        "  \n",
        "  Data_Embeddings = []\n",
        "  for row in range(data.shape[0]):\n",
        "#     print(row)\n",
        "    text = data.iloc[row][colname]\n",
        "    text_avg_embedding = Calculate_Glove_Embedding(glove_object, text)\n",
        "    Data_Embeddings.append(text_avg_embedding)\n",
        "  \n",
        "  Data_Text = data[colname]\n",
        "  Data_Embeddings = pd.DataFrame(Data_Embeddings)\n",
        "  \n",
        "  Text_Embedding_Map = pd.concat([Data_Text,Data_Embeddings], axis=1)\n",
        "  \n",
        "  if Output_Data_filepath:\n",
        "    Text_Embedding_Map.to_csv(Output_Data_filepath)\n",
        "  \n",
        "  return Text_Embedding_Map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-P1iRN63EEo",
        "colab_type": "code",
        "outputId": "985f8344-30aa-48e6-bf8a-1e6ccc02cd79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## Sample call to the fuction\n",
        "\n",
        "Text_Embedding_Map = Get_Glove_Embedding(\"/content/Trained_Glove_Model.pkl\", \"/content/Filtered_Positive_Data.csv\", \"Caption_Tokens\", \"/content/Positive_Glove_Embeddings.csv\")\n",
        "print(Text_Embedding_Map)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                         Caption_Tokens  ...       299\n",
            "0     walking feed sick new gear new brand partner f...  ...  0.008271\n",
            "1     one literally one zero calorie sugar free low ...  ...  0.031334\n",
            "2     thank listening article original post micro ar...  ...  0.023550\n",
            "3     climbing brush name today sad annoying men cli...  ...  0.002718\n",
            "4     since think told boring told high maintenance ...  ...  0.004441\n",
            "5     theme year crazy ride let many people go makin...  ...  0.015899\n",
            "6     long time recognize unpaid work housework bias...  ...  0.022081\n",
            "7     ich job ich gut mir r w hat sie na n sind ich ...  ... -0.054868\n",
            "8     original thank wait told place take wait peopl...  ...  0.010658\n",
            "9     random men offering unsolicited advice right w...  ...  0.012759\n",
            "10    globally unpaid work done spend three six per ...  ...  0.016958\n",
            "11    time celebrate felt like forever article writi...  ...  0.014341\n",
            "12    day combination day day think maybe warn peopl...  ...  0.021879\n",
            "13    today walk maria especially gratifying breakfa...  ... -0.003046\n",
            "14    right casual sex yet complete opposite men cas...  ... -0.003742\n",
            "15    day case tory education welfare housing social...  ...  0.016796\n",
            "16    exciting announcement laura back new book men ...  ...  0.010261\n",
            "17    despite fact day year affect every one u great...  ...  0.019083\n",
            "18    censorship vent incoming self censorship broug...  ...  0.003032\n",
            "19    lecture l ne plus lira livre par l de la de l ...  ... -0.093613\n",
            "20    lost trying please everyone loosing everyone e...  ...  0.022284\n",
            "21    news men hate may past year life project felt ...  ...  0.015448\n",
            "22    nach ich gut taxi ich den ich ich sah handy de...  ... -0.043965\n",
            "23    much work light hearted still personal vulnera...  ...  0.036946\n",
            "24               sir e die da wo sie drum sir e den sir  ... -0.077100\n",
            "25    kind like written throughout religious governm...  ... -0.009750\n",
            "26    seeming vendetta year old man learning dating ...  ...  0.005129\n",
            "27    post recently thrown jail dare try normalize f...  ...  0.014241\n",
            "28    often strong resilient like something wonderfu...  ...  0.006375\n",
            "29    time slow scroll going spend time follow inspi...  ...  0.021844\n",
            "...                                                 ...  ...       ...\n",
            "3618  part feeling vulnerable angry determined make ...  ...  0.002042\n",
            "3619  today known miller doe million read powerful i...  ...  0.018670\n",
            "3620  pretty post hey imposter syndrome go nothing w...  ... -0.005070\n",
            "3621  get despite told good enough take chance blood...  ...  0.026875\n",
            "3622  feel safe around love way look love strength f...  ... -0.014661\n",
            "3623  preach repost intersectional independent inter...  ... -0.055243\n",
            "3624  think mentality always constantly working dang...  ...  0.011114\n",
            "3625  best friend wishing could together enjoy egg j...  ...  0.021735\n",
            "3626  happiest smart strong talented kindhearted cre...  ... -0.006180\n",
            "3627  tell u answer find independent intersectional ...  ... -0.051947\n",
            "3628  know incredibly powerful people think time fle...  ... -0.001800\n",
            "3629  found amazing please read share write extremel...  ...  0.004926\n",
            "3630  new came person opening new merchandise soon s...  ...  0.036565\n",
            "3631  latest accomplishment independent intersection...  ... -0.052016\n",
            "3632  working every single spare minute outside day ...  ...  0.033900\n",
            "3633  back school going right list long arm attempt ...  ...  0.025108\n",
            "3634  feel three march later seen expect wear ugly p...  ... -0.037431\n",
            "3635  live way overcome must enough self discipline ...  ...  0.020881\n",
            "3636  past couple hearing many supporting happening ...  ...  0.010204\n",
            "3637  feeling inspired something pal love admire str...  ...  0.007949\n",
            "3638  message must independent intersectional femini...  ... -0.051358\n",
            "3639  independent intersectional feminist magazine g...  ... -0.056815\n",
            "3640  independent intersectional feminist magazine g...  ... -0.056815\n",
            "3641  current actress set stage fire fantastic perfo...  ...  0.002582\n",
            "3642  white stem notion white dominate racial hierar...  ... -0.027772\n",
            "3643  found ultimately truly pour heart believe even...  ... -0.004233\n",
            "3644  true start today year kick taking leap sooner ...  ...  0.036068\n",
            "3645  need world like support smash patriarchy peopl...  ... -0.000755\n",
            "3646  bitch independent intersectional feminist maga...  ... -0.054519\n",
            "3647  one u sexuality independent intersectional fem...  ... -0.048000\n",
            "\n",
            "[3648 rows x 301 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk6vk7K0uNCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Sample call to the fuction\n",
        "\n",
        "Text_Embedding_Map = Get_Glove_Embedding(\"/content/Trained_Glove_Model.pkl\", \"/content/Filtered_Positive_Data.csv\", \"Caption_Tokens\", \"/content/Positive_Glove_Embeddings.csv\")\n",
        "print(Text_Embedding_Map)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}